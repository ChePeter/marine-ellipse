{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f83a597b7fc45485e1d40ff42784dad44bb83871"
   },
   "source": [
    "Read data. A failed image is deleted and grouped by the number of ships.\n",
    "/you can choose another criterion, such as mask weight/\n",
    "validate images & masks is selected one picture cyclically from each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "e5094b4f067d50260b2bbeb889aef46996f3bd2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train files : 192555\n",
      "Test files : 15606\n",
      "3 9\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import skimage.io as io\n",
    "from tqdm import tqdm_notebook \n",
    "\n",
    "masks_train = pd.read_csv('../input/airbus-ship-detection/train_ship_segmentations_v2.csv')\n",
    "masks_train = masks_train[masks_train['ImageId'] != '6384c3e78.jpg']\n",
    "#https://www.kaggle.com/meaninglesslives/airbus-ship-detection-data-visualization\n",
    "masks_train['ship_count'] = masks_train.groupby('ImageId')['ImageId'].transform('count')\n",
    "masks_train.loc[masks_train['EncodedPixels'].isnull().values,'ship_count'] = 0  #see infocusp's comment\n",
    "_masks_train = pd.concat([\n",
    "                  masks_train[masks_train[\"ship_count\"] == 15].reset_index().drop(columns=['index']).\\\n",
    "                              reset_index().set_index(\"ImageId\"),\n",
    "                  masks_train[masks_train[\"ship_count\"] == 14].reset_index().drop(columns=['index']).\\\n",
    "                              reset_index().set_index(\"ImageId\"),\n",
    "                  masks_train[masks_train[\"ship_count\"] == 13].reset_index().drop(columns=['index']).\\\n",
    "                              reset_index().set_index(\"ImageId\"),\n",
    "                  masks_train[masks_train[\"ship_count\"] == 12].reset_index().drop(columns=['index']).\\\n",
    "                              reset_index().set_index(\"ImageId\"),\n",
    "                  masks_train[masks_train[\"ship_count\"] == 11].reset_index().drop(columns=['index']).\\\n",
    "                              reset_index().set_index(\"ImageId\"),\n",
    "                  masks_train[masks_train[\"ship_count\"] == 10].reset_index().drop(columns=['index']).\\\n",
    "                              reset_index().set_index(\"ImageId\"),\n",
    "                  masks_train[masks_train[\"ship_count\"] ==  9].reset_index().drop(columns=['index']).\\\n",
    "                              reset_index().set_index(\"ImageId\"),\n",
    "                  masks_train[masks_train[\"ship_count\"] ==  8].reset_index().drop(columns=['index']).\\\n",
    "                              reset_index().set_index(\"ImageId\"),\n",
    "                  masks_train[masks_train[\"ship_count\"] ==  7].reset_index().drop(columns=['index']).\\\n",
    "                              reset_index().set_index(\"ImageId\"),\n",
    "                  masks_train[masks_train[\"ship_count\"] ==  6].reset_index().drop(columns=['index']).\\\n",
    "                              reset_index().set_index(\"ImageId\"),\n",
    "                  masks_train[masks_train[\"ship_count\"] ==  5].reset_index().drop(columns=['index']).\\\n",
    "                              reset_index().set_index(\"ImageId\"),\n",
    "                  masks_train[masks_train[\"ship_count\"] ==  4].reset_index().drop(columns=['index']).\\\n",
    "                              reset_index().set_index(\"ImageId\"),\n",
    "                  masks_train[masks_train[\"ship_count\"] ==  3].reset_index().drop(columns=['index']).\\\n",
    "                              reset_index().set_index(\"ImageId\"),\n",
    "                  masks_train[masks_train[\"ship_count\"] ==  2].reset_index().drop(columns=['index']).\\\n",
    "                              reset_index().set_index(\"ImageId\"),\n",
    "                  masks_train[masks_train[\"ship_count\"] ==  1].reset_index().drop(columns=['index']).\\\n",
    "                              reset_index().set_index(\"ImageId\"),\n",
    "                  masks_train[masks_train[\"ship_count\"] ==  0].reset_index().drop(columns=['index']).\\\n",
    "                              reset_index().set_index(\"ImageId\") ]).\\\n",
    "    sort_values(\"index\", inplace=False)\n",
    "masks_train = _masks_train.drop(columns=['index']).reset_index()\n",
    "del(_masks_train)\n",
    "#print (masks_train.head())\n",
    "\n",
    "train_dir=\"../input/airbus-ship-detection/train_v2/\"\n",
    "train_file_names = masks_train['ImageId'].unique()\n",
    "train_file_names = train_file_names.tolist()\n",
    "print(\"Train files :\",len(train_file_names))\n",
    "\n",
    "\n",
    "test_dir=\"../input/airbus-ship-detection/test_v2/\"\n",
    "test_file_names=os.listdir(test_dir)\n",
    "print(\"Test files :\",len(test_file_names))\n",
    "\n",
    "train_len = len(train_file_names)\n",
    "test_len = len(test_file_names)\n",
    "\n",
    "o_size, w_size = 768, 256 # 384, 128, 64\n",
    "ow_coeff = int(o_size / w_size)\n",
    "\n",
    "if w_size*ow_coeff != o_size:\n",
    "    print ('w_ o_ size error')\n",
    "print (ow_coeff, ow_coeff*ow_coeff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "8a63661663d061d018fef1c82508f6d569963cd5"
   },
   "outputs": [],
   "source": [
    "# ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\n",
    "def rle_decode(mask_rle, shape=(768, 768)):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape).T  # Needed to align to RLE direction\n",
    "\n",
    "def get_mask_img(ImageId):\n",
    "    img_masks = masks_train['EncodedPixels'][masks_train['ImageId'] == ImageId].tolist()\n",
    "    mask_img = np.zeros((768, 768))\n",
    "    if len(img_masks)==1 and pd.isna(img_masks):\n",
    "        return mask_img\n",
    "    for mask in img_masks:\n",
    "        mask_img += rle_decode(mask)\n",
    "    return mask_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "3477ba7ec168a837db337ded740a4695a8952782"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144 15\n"
     ]
    }
   ],
   "source": [
    "f_val_len = 100 # depends on the power of your machine\n",
    "#f_val_imgs = np.memmap('/data/ssd1/airbus_ship/data/airbus_imgs_val.dat', dtype='float32', mode='w+', \\\n",
    "#                   shape=(f_val_len*ow_coeff*ow_coeff, w_size, w_size, 3))\n",
    "#f_val_masks = np.memmap('/data/ssd1/airbus_ship/data/airbus_masks_val.dat', dtype='float32', mode='w+', \\\n",
    "#                   shape=(f_val_len*ow_coeff*ow_coeff, w_size, w_size, 1))\n",
    "f_val_imgs = np.zeros((f_val_len*ow_coeff*ow_coeff, w_size, w_size, 3), dtype='float32')\n",
    "f_val_masks = np.zeros((f_val_len*ow_coeff*ow_coeff, w_size, w_size, 1), dtype='float32')\n",
    "# make initial validate sequence\n",
    "val_len = 0\n",
    "for k in range(16):\n",
    "    img = io.imread(train_dir+train_file_names[k])\n",
    "    mask=get_mask_img(train_file_names[k])\n",
    "    for i in range(ow_coeff):\n",
    "        for j in range(ow_coeff):\n",
    "            f_val_imgs[val_len,:,:,:] = img[w_size*i:w_size*i+w_size, w_size*j:w_size*j+w_size]/255.\n",
    "            f_val_masks[val_len,:,:,0] = mask[w_size*i:w_size*i+w_size, w_size*j:w_size*j+w_size]\n",
    "            val_len += 1\n",
    "raw_image_i = k\n",
    "    \n",
    "print (val_len,raw_image_i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dbcb3d65abfc5a16fcdc5ccdba3292dbb660a1a5"
   },
   "source": [
    "we have the initial sequence obtained from 15 images to which we will add new ones.\n",
    "\n",
    "load parts of keras and define a network\n",
    "\n",
    "https://www.kaggle.com/cpmpml/fast-iou-metric-in-numpy-and-tensorflow\n",
    "\n",
    "https://www.kaggle.com/shaojiaxin/u-net-with-simple-resnet-blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "679e5538d275200f14f6681761123e7833e6351f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dropout, Conv2D, MaxPooling2D, Activation\n",
    "from keras.layers import BatchNormalization,Add,concatenate,Conv2DTranspose\n",
    "from keras.layers import UpSampling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "#from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def get_iou_vector(A, B):\n",
    "    # Numpy version\n",
    "    \n",
    "    batch_size = A.shape[0]\n",
    "    metric = 0.0\n",
    "    for batch in range(batch_size):\n",
    "        t, p = A[batch], B[batch]\n",
    "        true = np.sum(t)\n",
    "        pred = np.sum(p)\n",
    "        \n",
    "        # deal with empty mask first\n",
    "        if true == 0:\n",
    "            metric += (pred == 0)\n",
    "            continue\n",
    "        \n",
    "        # non empty mask case.  Union is never empty \n",
    "        # hence it is safe to divide by its number of pixels\n",
    "        intersection = np.sum(t * p)\n",
    "        union = true + pred - intersection\n",
    "        iou = intersection / union\n",
    "        \n",
    "        # iou metrric is a stepwise approximation of the real iou over 0.5\n",
    "        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n",
    "        \n",
    "        metric += iou\n",
    "        \n",
    "    # teake the average over all images in batch\n",
    "    metric /= batch_size\n",
    "    return metric\n",
    "\n",
    "\n",
    "def my_iou_metric(label, pred):\n",
    "    # Tensorflow version\n",
    "    return tf.py_func(get_iou_vector, [label, pred > 0.5], tf.float64)\n",
    "\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "get_custom_objects().update({'my_iou_metric': my_iou_metric })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "317c08c0f517ffb88d62a46d89aecb366baabe4e"
   },
   "outputs": [],
   "source": [
    "def convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n",
    "    x = Conv2D(filters, size, strides=strides, padding=padding)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    if activation == True:\n",
    "        x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def residual_block(blockInput, num_filters=16):\n",
    "    x = Activation('relu')(blockInput)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = convolution_block(x, num_filters, (3,3) )\n",
    "    x = convolution_block(x, num_filters, (3,3), activation=False)\n",
    "    x = Add()([x, blockInput])\n",
    "    return x\n",
    "\n",
    "# Build model\n",
    "def build_model(input_layer, start_neurons, DropoutRatio = 0.5):\n",
    "    # 101 -> 50\n",
    "    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(input_layer)\n",
    "    conv1 = residual_block(conv1,start_neurons * 1)\n",
    "    conv1 = residual_block(conv1,start_neurons * 1)\n",
    "    conv1 = Activation('relu')(conv1)\n",
    "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "    pool1 = Dropout(DropoutRatio/2)(pool1)\n",
    "\n",
    "    # 50 -> 25\n",
    "    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(pool1)\n",
    "    conv2 = residual_block(conv2,start_neurons * 2)\n",
    "    conv2 = residual_block(conv2,start_neurons * 2)\n",
    "    conv2 = Activation('relu')(conv2)\n",
    "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "    pool2 = Dropout(DropoutRatio)(pool2)\n",
    "\n",
    "    # 25 -> 12\n",
    "    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(pool2)\n",
    "    conv3 = residual_block(conv3,start_neurons * 4)\n",
    "    conv3 = residual_block(conv3,start_neurons * 4)\n",
    "    conv3 = Activation('relu')(conv3)\n",
    "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
    "    pool3 = Dropout(DropoutRatio)(pool3)\n",
    "\n",
    "    # 12 -> 6\n",
    "    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(pool3)\n",
    "    conv4 = residual_block(conv4,start_neurons * 8)\n",
    "    conv4 = residual_block(conv4,start_neurons * 8)\n",
    "    conv4 = Activation('relu')(conv4)\n",
    "    pool4 = MaxPooling2D((2, 2))(conv4)\n",
    "    pool4 = Dropout(DropoutRatio)(pool4)\n",
    "\n",
    "    # Middle\n",
    "    convm = Conv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(pool4)\n",
    "    convm = residual_block(convm,start_neurons * 16)\n",
    "    convm = residual_block(convm,start_neurons * 16)\n",
    "    convm = Activation('relu')(convm)\n",
    "    \n",
    "    # 6 -> 12\n",
    "    deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n",
    "    uconv4 = concatenate([deconv4, conv4])\n",
    "    uconv4 = Dropout(DropoutRatio)(uconv4)\n",
    "    \n",
    "    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(uconv4)\n",
    "    uconv4 = residual_block(uconv4,start_neurons * 8)\n",
    "    uconv4 = residual_block(uconv4,start_neurons * 8)\n",
    "    uconv4 = Activation('relu')(uconv4)\n",
    "    \n",
    "    # 12 -> 25\n",
    "    deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n",
    "    #deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"valid\")(uconv4)\n",
    "    uconv3 = concatenate([deconv3, conv3])    \n",
    "    uconv3 = Dropout(DropoutRatio)(uconv3)\n",
    "    \n",
    "    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv3)\n",
    "    uconv3 = residual_block(uconv3,start_neurons * 4)\n",
    "    uconv3 = residual_block(uconv3,start_neurons * 4)\n",
    "    uconv3 = Activation('relu')(uconv3)\n",
    "\n",
    "    # 25 -> 50\n",
    "    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n",
    "    uconv2 = concatenate([deconv2, conv2])\n",
    "        \n",
    "    uconv2 = Dropout(DropoutRatio)(uconv2)\n",
    "    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv2)\n",
    "    uconv2 = residual_block(uconv2,start_neurons * 2)\n",
    "    uconv2 = residual_block(uconv2,start_neurons * 2)\n",
    "    uconv2 = Activation('relu')(uconv2)\n",
    "    \n",
    "    # 50 -> 101\n",
    "    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n",
    "    #deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"valid\")(uconv2)\n",
    "    uconv1 = concatenate([deconv1, conv1])\n",
    "    \n",
    "    uconv1 = Dropout(DropoutRatio)(uconv1)\n",
    "    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv1)\n",
    "    uconv1 = residual_block(uconv1,start_neurons * 1)\n",
    "    uconv1 = residual_block(uconv1,start_neurons * 1)\n",
    "    uconv1 = Activation('relu')(uconv1)\n",
    "    \n",
    "    uconv1 = Dropout(DropoutRatio/2)(uconv1)\n",
    "    output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv1)\n",
    "    \n",
    "    return output_layer\n",
    "\n",
    "input_layer = Input((w_size, w_size, 3))\n",
    "output_layer = build_model(input_layer, 16, 0.5)\n",
    "\n",
    "model = Model(input_layer, output_layer)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[my_iou_metric])\n",
    "#model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "41d8a4bcf3d284a8a00c66140a46ee0cd66c0918"
   },
   "source": [
    "Here we take the next image and check how the network trained in the previous frames is able to predict the mask.\n",
    "If the accuracy is acceptable, then this image(crop) is rejected, if the network could not calculate the mask, then this image(crop) is useful to be included in validate sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "79598edea6793b7d4caafb73bd9c355c5932ff5c",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size = ow_coeff*ow_coeff*2\n",
    "precision = 0.85\n",
    "\n",
    "#f_m_save = \"./val_prep_0.model\"\n",
    "f_w_save = \"../input/weights0/val_prep.weights\" # my pretrained weights\n",
    "model.load_weights(f_w_save, by_name=False)\n",
    "\n",
    "K.set_value(model.optimizer.lr, 1e-4)\n",
    "lr = K.get_value(model.optimizer.lr)\n",
    "\n",
    "while True:\n",
    "    print(time.ctime())\n",
    "# network training in initial or added sequence\n",
    "    fit = model.fit(f_val_imgs[:val_len], f_val_masks[:val_len],\n",
    "                    batch_size=batch_size, \n",
    "                    epochs=1, \n",
    "                    verbose=2\n",
    "                   )\n",
    "    \n",
    "    current_accu = fit.history['my_iou_metric'][0]\n",
    "    current_loss = fit.history['loss'][0]\n",
    "    if current_accu > precision:\n",
    "#        model.save(f_m_save)\n",
    "#        model.save_weights(f_w_save)\n",
    "        while True:\n",
    "            new_img_test = 0\n",
    "            img = io.imread(train_dir+train_file_names[raw_image_i])\n",
    "            mask=get_mask_img(train_file_names[raw_image_i])\n",
    "            print (\"ImageId\",train_file_names[raw_image_i])\n",
    "            raw_image_i += 1\n",
    "            print (\"next image\",raw_image_i)\n",
    "            for i in range(ow_coeff):\n",
    "                for j in range(ow_coeff):\n",
    "                    _img = img[w_size*i:w_size*i+w_size, w_size*j:w_size*j+w_size,:]/255.\n",
    "                    _img = _img.reshape(1,w_size,w_size,3)\n",
    "                    _mask = mask[w_size*i:w_size*i+w_size, w_size*j:w_size*j+w_size]\n",
    "                    _mask = _mask.reshape(1,w_size,w_size,1)\n",
    "                    \n",
    "                    _pred = model.predict(_img)\n",
    "                    val_iou = get_iou_vector(_mask, _pred > 0.5)\n",
    "                    \n",
    "                    if val_iou < precision*0.9:\n",
    "                        # You can look at the images(crop) that is added\n",
    "                        #\n",
    "                        #fig, axes = plt.subplots(1, 3, figsize=(30, 10))\n",
    "                        #axes[0].set_axis_off()\n",
    "                        #axes[1].set_axis_off()\n",
    "                        #axes[2].set_axis_off()\n",
    "                        #axes[1].set_title(val_iou, fontsize=20)\n",
    "                        #axes[0].imshow(_img.squeeze())\n",
    "                        #axes[1].imshow(_pred.squeeze())\n",
    "                        #axes[2].imshow(_mask.squeeze())\n",
    "                        #\n",
    "                        #plt.show(block=True)\n",
    "                        new_img_test = 1\n",
    "                        f_val_imgs[val_len,:,:,:] = _img[0,:,:,:]\n",
    "                        f_val_masks[val_len,:,:,0] = _mask[0,:,:,0]\n",
    "                        val_len += 1\n",
    "                        print (\"new validate lenght\", val_len)\n",
    "                        #f_val_imgs.flush()\n",
    "                        #f_val_masks.flush()\n",
    "# If the frame is added, then you need to clarify the network weights.\n",
    "# If not then prepare next image\n",
    "            if new_img_test > 0:\n",
    "                break           \n",
    "\n",
    "    if raw_image_i >= train_len:\n",
    "        raw_image_i = 0\n",
    "    if val_len >= f_val_len:\n",
    "        break\n",
    "\n",
    "#del(f_val_imgs)\n",
    "#del(f_val_masks)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
